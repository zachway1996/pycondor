{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to the PyCondor documentation\n\n\nPyCondor\n (Python HTCondor) is a tool that helps build and submit HTCondor jobs in a straight-forward manner with minimal hassle.\n\n\nMotivation\n\n\nHTCondor\n is a an open-source workload management system for high-throughput computing tasks developed at the University of Wisconsin\u2013Madison. It is an incredibly useful and versatile tool. However, the process of submitting jobs to HTCondor, especially when there are inter-job dependencies, can quickly become both tedious and complex. PyCondor is a tool to help streamline this job submission process through a user-friendly API and built-in functionality to automate common tasks.\n\n\nUseful Links\n\n\n\n\nDocumentation: \nhttp://www.jamesbourbeau.com/pycondor\n\n\nGitHub repository: \nhttps://github.com/jrbourbeau/pycondor\n\n\nPyPI: \nhttps://pypi.python.org/pypi/PyCondor\n\n\nIssue tracker: \nhttps://github.com/jrbourbeau/pycondor/issues\n\n\n\n\nExample\n\n\nWith just a couple lines of code, you can get PyCondor up and running!\n\n\nimport\n \npycondor\n\n\n\n# Setting up a PyCondor Job\n\n\njob\n \n=\n \npycondor\n.\nJob\n(\nexamplejob\n,\n \nscript.py\n)\n\n\n# Write all necessary submit files and submit job to Condor\n\n\njob\n.\nbuild_submit\n()", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-the-pycondor-documentation", 
            "text": "PyCondor  (Python HTCondor) is a tool that helps build and submit HTCondor jobs in a straight-forward manner with minimal hassle.", 
            "title": "Welcome to the PyCondor documentation"
        }, 
        {
            "location": "/#motivation", 
            "text": "HTCondor  is a an open-source workload management system for high-throughput computing tasks developed at the University of Wisconsin\u2013Madison. It is an incredibly useful and versatile tool. However, the process of submitting jobs to HTCondor, especially when there are inter-job dependencies, can quickly become both tedious and complex. PyCondor is a tool to help streamline this job submission process through a user-friendly API and built-in functionality to automate common tasks.", 
            "title": "Motivation"
        }, 
        {
            "location": "/#useful-links", 
            "text": "Documentation:  http://www.jamesbourbeau.com/pycondor  GitHub repository:  https://github.com/jrbourbeau/pycondor  PyPI:  https://pypi.python.org/pypi/PyCondor  Issue tracker:  https://github.com/jrbourbeau/pycondor/issues", 
            "title": "Useful Links"
        }, 
        {
            "location": "/#example", 
            "text": "With just a couple lines of code, you can get PyCondor up and running!  import   pycondor  # Setting up a PyCondor Job  job   =   pycondor . Job ( examplejob ,   script.py )  # Write all necessary submit files and submit job to Condor  job . build_submit ()", 
            "title": "Example"
        }, 
        {
            "location": "/installation/", 
            "text": "Installing PyCondor\n\n\nPyCondor can be easily installed via pip\n\n\npip install pycondor\n\n\n\n\n\nIn addition, you can also install PyCondor by downloading the \nproject .tar file from the Python Package Index\n, unzip the download, navigate to the PyCondor project directory and run\n\n\npython setup.py install\n\n\n\n\n\nTo upgrade an existing version of PyCondor, execute the following\n\n\npip install pycondor --upgrade\n\n\n\n\n\nLastly, you can always fork the \nGitHub repository\n and install locally via\n\n\npython setup.py install", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#installing-pycondor", 
            "text": "PyCondor can be easily installed via pip  pip install pycondor  In addition, you can also install PyCondor by downloading the  project .tar file from the Python Package Index , unzip the download, navigate to the PyCondor project directory and run  python setup.py install  To upgrade an existing version of PyCondor, execute the following  pip install pycondor --upgrade  Lastly, you can always fork the  GitHub repository  and install locally via  python setup.py install", 
            "title": "Installing PyCondor"
        }, 
        {
            "location": "/Job/", 
            "text": "Job(name, executable, error=None, log=None, output=None, submit=cwd,\n    request_memory=None, request_disk=None, request_cpus=None, getenv=True,\n    universe=\nvanilla\n, initialdir=None, notification=\nnever\n, requirements=None,\n    queue=None, extra_lines=None, use_unique_id=False, verbose=0)\n\n\n\n\n\nThe \nJob\n object consists of an executable to run on Condor, any specifications to include in the corresponding submit file (e.g. memory request, universe execution environment, etc.), and any arguments that you would like to pass to the executable. \nJob\n objects can be submitted directly to HTCondor, or can be included in a \nDagman\n object for additional job management functionality.\n\n\nParameters\n\n\n\n\n\n\nname\n : \nstr\n\n\nName of the Job instance. This will also be the name of the corresponding error, log, output, and submit files associated with this job.\n\n\n\n\n\n\nexecutable\n : \nstr\n\n\nPath to corresponding executable for Job.\n\n\n\n\n\n\nerror\n : \nstr\n (default: \nNone\n)\n\n\nPath to directory where condor job error files will be written.\n\n\n\n\n\n\nlog\n : \nstr\n (default: \nNone\n)\n\n\nPath to directory where condor job log files will be written.\n\n\n\n\n\n\noutput\n : \nstr\n (default: \nNone\n)\n\n\nPath to directory where condor job output files will be written.\n\n\n\n\n\n\nsubmit\n : \nstr\n (default: current directory)\n\n\nPath to directory where condor job submit files will be written. (Defaults to the directory was the job was submitted from).\n\n\n\n\n\n\nrequest_memory\n : \nstr\n (default: \nNone\n)\n\n\nMemory request to be included in submit file.\n\n\n\n\n\n\nrequest_disk\n : \nstr\n (default: \nNone\n)\n\n\nDisk request to be included in submit file.\n\n\n\n\n\n\nrequest_cpus\n : \nint\n (default: \nNone\n)\n\n\n(Added in version 0.1.0)\n\n\nNumber of CPUs to request in submit file.\n\n\n\n\n\n\ngetenv\n : \nbool\n (default: \nTrue\n)\n\n\nWhether or not to use the current environment settings when running the job.\n\n\n\n\n\n\nuniverse\n : \nstr\n (default: \n'vanilla'\n)\n\n\nUniverse execution environment to be specified in submit file.\n\n\n\n\n\n\ninitialdir\n : \nstr\n (default: \nNone\n)\n\n\nInitial directory for relative paths (defaults to the directory was the job was submitted from).\n\n\n\n\n\n\nnotification\n : \nstr\n (default: \n'never'\n)\n\n\nE-mail notification preference.\n\n\n\n\n\n\nrequirements\n : \nstr\n (default: \nNone\n)\n\n\nAdditional requirements to be included in ClassAd.\n\n\n\n\n\n\nqueue\n : \nint\n (default: \nNone\n)\n\n\nInteger specifying how many times you would like this job to run.\n\n\n\n\n\n\nextra_lines\n : \nlist\n (default: \nNone\n)\n\n\nList of additional lines to be added to submit file.\n\n\n\n\n\n\nuse_unique_id\n : \nbool\n (default: \nFalse\n)\n\n\n(Added in version 0.1.1)\n\n\nOption to have a separate set of error, output, and log files for each argument in Job.\n\n\n\n\n\n\nverbose\n : \nint\n (default: 0)\n\n\nLevel of logging verbosity.\n\n\n\n\n0 \n warning (least verbose)\n\n\n1 \n info\n\n\n2 \n debug (most verbose)\n\n\n\n\n\n\n\n\nAttributes\n\n\n\n\n\n\nargs\n : \nlist\n (default: \n[]\n)\n\n\nList of command-line arguments that will be passed to the Job executable.\n\n\n\n\n\n\nparents\n : \nlist\n (default: \n[]\n)\n\n\nOnly applies when Job is in a Dagman\n. List of parent Jobs. Dagman will ensure that Jobs in the parents list will complete before this Job is submitted to HTCondor.\n\n\n\n\n\n\nchildren\n : \nlist\n (default: \n[]\n)\n\n\nOnly applies when Job is in a Dagman\n. List of child Jobs. Dagman will ensure that Jobs in the children list will be submitted to HTCondor only after this Job has completed.\n\n\n\n\n\n\nMethods\n\n\n\n\n\n\nadd_arg(arg)\n\n\nParameters:\n\n\n\n\n\n\narg\n : \nstr\n\n\nArgument to append to Job \nargs\n list.\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\nself\n : \nJob\n\n\nReturns self.\n\n\n\n\n\n\n\n\n\n\nadd_parent(job)\n\n\nParameters:\n\n\n\n\n\n\njob\n : \nJob\n\n\nJob to append to the \nparents\n list.\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\nself\n : \nJob\n\n\nReturns self.\n\n\n\n\n\n\n\n\n\n\nadd_child(job)\n\n\nParameters:\n\n\n\n\n\n\njob\n : \nJob\n\n\nJob to append to the \nchildren\n list.\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\nself\n : \nJob\n\n\nReturns self.\n\n\n\n\n\n\n\n\n\n\nbuild(makedirs, fancyname)\n\n\nParameters:\n\n\n\n\n\n\nmakedirs\n : \nbool\n (default: \nTrue\n)\n\n\nIf specified Job directories (e.g. error, output, log, submit) don't exist, create them.\n\n\n\n\n\n\nfancyname\n : \nbool\n (default: \nTrue\n)\n\n\nAppends the date and unique id number to error, log, output, and submit files. For example, instead of \njobname.submit\n the submit file becomes \njobname_YYYYMMD_id\n. This is useful when running several Jobs of the same name.\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\nself\n : \nJob\n\n\nReturns self.\n\n\n\n\n\n\n\n\n\n\nsubmit_job(kwargs)\n\n\nParameters:\n\n\n\n\n\n\nkwargs\n : \ndict\n (default: \n{}\n)\n\n\nAny additional options you would like specified when \ncondor_submit\n is called (see HTCondor \ndocumentation\n for possible options). For example, if you would like to add \n-maxjobs 1000\n to the \ncondor_submit\n command, then \nkwargs = {'-maxjobs': 1000}\n.\n\n\n\n\n\n\n\n\n\n\nbuild_submit(makedirs, fancyname, kwargs)\n\n\nConvenience method. First calls \nbuild()\n then \nsubmit_job()\n, with appropriate arguments.", 
            "title": "Job"
        }, 
        {
            "location": "/Job/#parameters", 
            "text": "name  :  str  Name of the Job instance. This will also be the name of the corresponding error, log, output, and submit files associated with this job.    executable  :  str  Path to corresponding executable for Job.    error  :  str  (default:  None )  Path to directory where condor job error files will be written.    log  :  str  (default:  None )  Path to directory where condor job log files will be written.    output  :  str  (default:  None )  Path to directory where condor job output files will be written.    submit  :  str  (default: current directory)  Path to directory where condor job submit files will be written. (Defaults to the directory was the job was submitted from).    request_memory  :  str  (default:  None )  Memory request to be included in submit file.    request_disk  :  str  (default:  None )  Disk request to be included in submit file.    request_cpus  :  int  (default:  None )  (Added in version 0.1.0)  Number of CPUs to request in submit file.    getenv  :  bool  (default:  True )  Whether or not to use the current environment settings when running the job.    universe  :  str  (default:  'vanilla' )  Universe execution environment to be specified in submit file.    initialdir  :  str  (default:  None )  Initial directory for relative paths (defaults to the directory was the job was submitted from).    notification  :  str  (default:  'never' )  E-mail notification preference.    requirements  :  str  (default:  None )  Additional requirements to be included in ClassAd.    queue  :  int  (default:  None )  Integer specifying how many times you would like this job to run.    extra_lines  :  list  (default:  None )  List of additional lines to be added to submit file.    use_unique_id  :  bool  (default:  False )  (Added in version 0.1.1)  Option to have a separate set of error, output, and log files for each argument in Job.    verbose  :  int  (default: 0)  Level of logging verbosity.   0   warning (least verbose)  1   info  2   debug (most verbose)", 
            "title": "Parameters"
        }, 
        {
            "location": "/Job/#attributes", 
            "text": "args  :  list  (default:  [] )  List of command-line arguments that will be passed to the Job executable.    parents  :  list  (default:  [] )  Only applies when Job is in a Dagman . List of parent Jobs. Dagman will ensure that Jobs in the parents list will complete before this Job is submitted to HTCondor.    children  :  list  (default:  [] )  Only applies when Job is in a Dagman . List of child Jobs. Dagman will ensure that Jobs in the children list will be submitted to HTCondor only after this Job has completed.", 
            "title": "Attributes"
        }, 
        {
            "location": "/Job/#methods", 
            "text": "add_arg(arg)  Parameters:    arg  :  str  Argument to append to Job  args  list.    Returns:    self  :  Job  Returns self.      add_parent(job)  Parameters:    job  :  Job  Job to append to the  parents  list.    Returns:    self  :  Job  Returns self.      add_child(job)  Parameters:    job  :  Job  Job to append to the  children  list.    Returns:    self  :  Job  Returns self.      build(makedirs, fancyname)  Parameters:    makedirs  :  bool  (default:  True )  If specified Job directories (e.g. error, output, log, submit) don't exist, create them.    fancyname  :  bool  (default:  True )  Appends the date and unique id number to error, log, output, and submit files. For example, instead of  jobname.submit  the submit file becomes  jobname_YYYYMMD_id . This is useful when running several Jobs of the same name.    Returns:    self  :  Job  Returns self.      submit_job(kwargs)  Parameters:    kwargs  :  dict  (default:  {} )  Any additional options you would like specified when  condor_submit  is called (see HTCondor  documentation  for possible options). For example, if you would like to add  -maxjobs 1000  to the  condor_submit  command, then  kwargs = {'-maxjobs': 1000} .      build_submit(makedirs, fancyname, kwargs)  Convenience method. First calls  build()  then  submit_job() , with appropriate arguments.", 
            "title": "Methods"
        }, 
        {
            "location": "/Dagman/", 
            "text": "Dagman(name, submit=cwd, extra_lines=None, verbose=0)\n\n\n\n\n\nThe \nDagman\n object acts as a container for \nJob\n objects. \nDagman\n objects also handle any inter-job dependencies, such as parent-child relationships between jobs.\n\n\nParameters\n\n\n\n\n\n\nname\n : \nstr\n\n\nName of the Dagman instance. This will also be the name of the corresponding error, log, output, and submit files associated with this Dagman.\n\n\n\n\n\n\nsubmit\n : \nstr\n (default: current directory)\n\n\nPath to directory where condor dagman submit files will be written. (Defaults to the directory was the job was submitted from).\n\n\n\n\n\n\nextra_lines\n : \nlist\n (default: \nNone\n)\n\n\nList of additional lines to be added to submit file.\n\n\n\n\n\n\nverbose\n : \nint\n (default: 0)\n\n\nLevel of logging verbosity.\n\n\n\n\n0 \n warning (least verbose)\n\n\n1 \n info\n\n\n2 \n debug (most verbose)\n\n\n\n\n\n\n\n\nAttributes\n\n\n\n\n\n\njobs\n : \nlist\n (default: \n[]\n)\n\n\nList of Job objects to be included in DAGMan submit file.\n\n\n\n\n\n\nMethods\n\n\n\n\n\n\nadd_job(job)\n\n\nParameters:\n\n\n\n\n\n\njob\n : \nJob\n\n\nJob to append to the \njobs\n list.\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\nself\n : \nJob\n\n\nReturns self.\n\n\n\n\n\n\n\n\n\n\nbuild(makedirs, fancyname)\n\n\nParameters:\n\n\n\n\n\n\nmakedirs\n : \nbool\n (default: \nTrue\n)\n\n\nIf specified Dagman and/or Job directories (e.g. error, output, log, submit) don't exist, create them.\n\n\n\n\n\n\nfancyname\n : \nbool\n (default: \nTrue\n)\n\n\nAppends the date and unique id number to error, log, output, and submit files. For example, instead of \njobname.submit\n the submit file becomes \njobname_YYYYMMD_id\n. This is useful when running several Jobs of the same name.\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\nself\n : \nJob\n\n\nReturns self.\n\n\n\n\n\n\n\n\n\n\nsubmit_dag(kwargs)\n\n\nParameters:\n\n\n\n\n\n\nkwargs\n : \ndict\n (default: \n{}\n)\n\n\nAny additional options you would like specified when \ncondor_submit_dag\n is called (see HTCondor \ndocumentation\n for possible options). For example, if you would like to add \n-maxjobs 1000\n to the \ncondor_submit_dag\n command, then \nkwargs = {'-maxjobs': 1000}\n.\n\n\n\n\n\n\n\n\n\n\nbuild_submit(makedirs, fancyname, kwargs)\n\n\nConvenience method. First calls \nbuild()\n then \nsubmit_dag()\n, with appropriate arguments.", 
            "title": "Dagman"
        }, 
        {
            "location": "/Dagman/#parameters", 
            "text": "name  :  str  Name of the Dagman instance. This will also be the name of the corresponding error, log, output, and submit files associated with this Dagman.    submit  :  str  (default: current directory)  Path to directory where condor dagman submit files will be written. (Defaults to the directory was the job was submitted from).    extra_lines  :  list  (default:  None )  List of additional lines to be added to submit file.    verbose  :  int  (default: 0)  Level of logging verbosity.   0   warning (least verbose)  1   info  2   debug (most verbose)", 
            "title": "Parameters"
        }, 
        {
            "location": "/Dagman/#attributes", 
            "text": "jobs  :  list  (default:  [] )  List of Job objects to be included in DAGMan submit file.", 
            "title": "Attributes"
        }, 
        {
            "location": "/Dagman/#methods", 
            "text": "add_job(job)  Parameters:    job  :  Job  Job to append to the  jobs  list.    Returns:    self  :  Job  Returns self.      build(makedirs, fancyname)  Parameters:    makedirs  :  bool  (default:  True )  If specified Dagman and/or Job directories (e.g. error, output, log, submit) don't exist, create them.    fancyname  :  bool  (default:  True )  Appends the date and unique id number to error, log, output, and submit files. For example, instead of  jobname.submit  the submit file becomes  jobname_YYYYMMD_id . This is useful when running several Jobs of the same name.    Returns:    self  :  Job  Returns self.      submit_dag(kwargs)  Parameters:    kwargs  :  dict  (default:  {} )  Any additional options you would like specified when  condor_submit_dag  is called (see HTCondor  documentation  for possible options). For example, if you would like to add  -maxjobs 1000  to the  condor_submit_dag  command, then  kwargs = {'-maxjobs': 1000} .      build_submit(makedirs, fancyname, kwargs)  Convenience method. First calls  build()  then  submit_dag() , with appropriate arguments.", 
            "title": "Methods"
        }, 
        {
            "location": "/examples/", 
            "text": "Examples\n\n\nAll of the following examples use a dummy script, \nsavelist.py\n, that creates and saves a Python \nlist\n. \nsavelist.py\n has a command-line argument \n--length\n that specifies how many items to generate in the list (default: 10). The script is located in the \nexamples/\n directory in the \nPyCondor repository\n.\n\n\nJob examples\n\n\nBasic Job submission\n\n\nimport\n \npycondor\n\n\n\n# Declare the error, output, log, and submit directories for Condor Job\n\n\nerror\n \n=\n \ncondor/error\n\n\noutput\n \n=\n \ncondor/output\n\n\nlog\n \n=\n \ncondor/log\n\n\nsubmit\n \n=\n \ncondor/submit\n\n\n\n# Setting up a PyCondor Job\n\n\njob\n \n=\n \npycondor\n.\nJob\n(\nexamplejob\n,\n \nsavelist.py\n,\n\n               \nerror\n=\nerror\n,\n \noutput\n=\noutput\n,\n\n               \nlog\n=\nlog\n,\n \nsubmit\n=\nsubmit\n,\n \nverbose\n=\n2\n)\n\n\n# Write all necessary submit files and submit job to Condor\n\n\njob\n.\nbuild_submit\n()\n\n\n\n\n\n\nAdding arguments to a Job\n\n\nimport\n \npycondor\n\n\n\n# Declare the error, output, log, and submit directories for Condor Job\n\n\nerror\n \n=\n \ncondor/error\n\n\noutput\n \n=\n \ncondor/output\n\n\nlog\n \n=\n \ncondor/log\n\n\nsubmit\n \n=\n \ncondor/submit\n\n\n\n# Setting up a PyCondor Job\n\n\njob\n \n=\n \npycondor\n.\nJob\n(\nexamplejob\n,\n \nsavelist.py\n,\n\n               \nerror\n=\nerror\n,\n \noutput\n=\noutput\n,\n\n               \nlog\n=\nlog\n,\n \nsubmit\n=\nsubmit\n,\n \nverbose\n=\n2\n)\n\n\n# Adding arguments to job\n\n\njob\n.\nadd_arg\n(\n--length 50\n)\n\n\njob\n.\nadd_arg\n(\n--length 100\n)\n\n\njob\n.\nadd_arg\n(\n--length 200\n)\n\n\n# Write all necessary submit files and submit job to Condor\n\n\njob\n.\nbuild_submit\n()\n\n\n\n\n\n\n\n\nDagman examples\n\n\nAdding Jobs to a Dagman\n\n\nimport\n \npycondor\n\n\n\n# Declare the error, output, log, and submit directories for Condor Job\n\n\nerror\n \n=\n \ncondor/error\n\n\noutput\n \n=\n \ncondor/output\n\n\nlog\n \n=\n \ncondor/log\n\n\nsubmit\n \n=\n \ncondor/submit\n\n\n\n# Setting up a PyCondor Job\n\n\njob\n \n=\n \npycondor\n.\nJob\n(\nexamplejob\n,\n \nsavelist.py\n,\n\n               \nerror\n=\nerror\n,\n \noutput\n=\noutput\n,\n\n               \nlog\n=\nlog\n,\n \nsubmit\n=\nsubmit\n,\n \nverbose\n=\n2\n)\n\n\n# Adding arguments to job\n\n\njob\n.\nadd_arg\n(\n--length 50\n)\n\n\njob\n.\nadd_arg\n(\n--length 100\n)\n\n\njob\n.\nadd_arg\n(\n--length 200\n)\n\n\n\n# Setting up a PyCondor Dagman\n\n\ndagman\n \n=\n \npycondor\n.\nDagman\n(\nexampledagman\n,\n \nsubmit\n=\nsubmit\n,\n \nverbose\n=\n2\n)\n\n\n# Add job to dagman\n\n\ndagman\n.\nadd_job\n(\njob\n)\n\n\n# Write all necessary submit files and submit job to Condor\n\n\ndagman\n.\nbuild_submit\n()\n\n\n\n\n\n\nAdd inter-job dependencies\n\n\nimport\n \npycondor\n\n\n\n# Declare the error, output, log, and submit directories for Condor Job\n\n\nerror\n \n=\n \ncondor/error\n\n\noutput\n \n=\n \ncondor/output\n\n\nlog\n \n=\n \ncondor/log\n\n\nsubmit\n \n=\n \ncondor/submit\n\n\n\n# Setting up first PyCondor Job\n\n\njob1\n \n=\n \npycondor\n.\nJob\n(\nexamplejob1\n,\n \nsavelist.py\n,\n\n               \nerror\n=\nerror\n,\n \noutput\n=\noutput\n,\n\n               \nlog\n=\nlog\n,\n \nsubmit\n=\nsubmit\n,\n \nverbose\n=\n2\n)\n\n\n# Adding arguments to job1\n\n\njob1\n.\nadd_arg\n(\n--length 100\n)\n\n\n# Setting up second PyCondor Job\n\n\njob2\n \n=\n \npycondor\n.\nJob\n(\nexamplejob2\n,\n \nsavelist.py\n,\n\n               \nerror\n=\nerror\n,\n \noutput\n=\noutput\n,\n\n               \nlog\n=\nlog\n,\n \nsubmit\n=\nsubmit\n,\n \nverbose\n=\n2\n)\n\n\n# Adding arguments to job1\n\n\njob2\n.\nadd_arg\n(\n--length 200\n)\n\n\n\n# Add interjob reltionship.\n\n\n# Ensure that job1 is complete before job2 starts\n\n\njob1\n.\nadd_child\n(\njob2\n)\n\n\n\n# Setting up a PyCondor Dagman\n\n\ndagman\n \n=\n \npycondor\n.\nDagman\n(\nexampledagman\n,\n \nsubmit\n=\nsubmit\n,\n \nverbose\n=\n2\n)\n\n\n# Add jobs to dagman\n\n\ndagman\n.\nadd_job\n(\njob1\n)\n\n\ndagman\n.\nadd_job\n(\njob2\n)\n\n\n# Write all necessary submit files and submit job to Condor\n\n\ndagman\n.\nbuild_submit\n()", 
            "title": "Examples"
        }, 
        {
            "location": "/examples/#examples", 
            "text": "All of the following examples use a dummy script,  savelist.py , that creates and saves a Python  list .  savelist.py  has a command-line argument  --length  that specifies how many items to generate in the list (default: 10). The script is located in the  examples/  directory in the  PyCondor repository .", 
            "title": "Examples"
        }, 
        {
            "location": "/examples/#job-examples", 
            "text": "", 
            "title": "Job examples"
        }, 
        {
            "location": "/examples/#basic-job-submission", 
            "text": "import   pycondor  # Declare the error, output, log, and submit directories for Condor Job  error   =   condor/error  output   =   condor/output  log   =   condor/log  submit   =   condor/submit  # Setting up a PyCondor Job  job   =   pycondor . Job ( examplejob ,   savelist.py , \n                error = error ,   output = output , \n                log = log ,   submit = submit ,   verbose = 2 )  # Write all necessary submit files and submit job to Condor  job . build_submit ()", 
            "title": "Basic Job submission"
        }, 
        {
            "location": "/examples/#adding-arguments-to-a-job", 
            "text": "import   pycondor  # Declare the error, output, log, and submit directories for Condor Job  error   =   condor/error  output   =   condor/output  log   =   condor/log  submit   =   condor/submit  # Setting up a PyCondor Job  job   =   pycondor . Job ( examplejob ,   savelist.py , \n                error = error ,   output = output , \n                log = log ,   submit = submit ,   verbose = 2 )  # Adding arguments to job  job . add_arg ( --length 50 )  job . add_arg ( --length 100 )  job . add_arg ( --length 200 )  # Write all necessary submit files and submit job to Condor  job . build_submit ()", 
            "title": "Adding arguments to a Job"
        }, 
        {
            "location": "/examples/#dagman-examples", 
            "text": "", 
            "title": "Dagman examples"
        }, 
        {
            "location": "/examples/#adding-jobs-to-a-dagman", 
            "text": "import   pycondor  # Declare the error, output, log, and submit directories for Condor Job  error   =   condor/error  output   =   condor/output  log   =   condor/log  submit   =   condor/submit  # Setting up a PyCondor Job  job   =   pycondor . Job ( examplejob ,   savelist.py , \n                error = error ,   output = output , \n                log = log ,   submit = submit ,   verbose = 2 )  # Adding arguments to job  job . add_arg ( --length 50 )  job . add_arg ( --length 100 )  job . add_arg ( --length 200 )  # Setting up a PyCondor Dagman  dagman   =   pycondor . Dagman ( exampledagman ,   submit = submit ,   verbose = 2 )  # Add job to dagman  dagman . add_job ( job )  # Write all necessary submit files and submit job to Condor  dagman . build_submit ()", 
            "title": "Adding Jobs to a Dagman"
        }, 
        {
            "location": "/examples/#add-inter-job-dependencies", 
            "text": "import   pycondor  # Declare the error, output, log, and submit directories for Condor Job  error   =   condor/error  output   =   condor/output  log   =   condor/log  submit   =   condor/submit  # Setting up first PyCondor Job  job1   =   pycondor . Job ( examplejob1 ,   savelist.py , \n                error = error ,   output = output , \n                log = log ,   submit = submit ,   verbose = 2 )  # Adding arguments to job1  job1 . add_arg ( --length 100 )  # Setting up second PyCondor Job  job2   =   pycondor . Job ( examplejob2 ,   savelist.py , \n                error = error ,   output = output , \n                log = log ,   submit = submit ,   verbose = 2 )  # Adding arguments to job1  job2 . add_arg ( --length 200 )  # Add interjob reltionship.  # Ensure that job1 is complete before job2 starts  job1 . add_child ( job2 )  # Setting up a PyCondor Dagman  dagman   =   pycondor . Dagman ( exampledagman ,   submit = submit ,   verbose = 2 )  # Add jobs to dagman  dagman . add_job ( job1 )  dagman . add_job ( job2 )  # Write all necessary submit files and submit job to Condor  dagman . build_submit ()", 
            "title": "Add inter-job dependencies"
        }, 
        {
            "location": "/CHANGELOG/", 
            "text": "Release Notes\n\n\nVersion 0.1.1\n\n\nChanges\n:\n\n\n\n\nAdds \nuse_unique_id\n option when creating a Job object. This will then create a separate error, log, and output file for each of the arguments in the Job \nargs\n list.\n\n\nAdds \nextra_lines\n option when creating a Dagman object (similar to the Job object).\n\n\nReplaces all occurances of \nos.system()\n with \nsubprocess.Popen()\n. This won't affect anything the user touches, just modernizing under-the-hood stuff.\n\n\n\n\nVersion 0.1.0\n\n\nChanges\n:\n\n\n\n\nAdds \nrequest_cpus\n attribute to Job object to make it easier to request a specified number of CPUs.\n\n\nAdds \npycondor.get_queue()\n feature to get \ncondor_q\n information.\n\n\nJob and Dagman object methods now return \nself\n.\n\n\nFixed typo in logger formatting.", 
            "title": "Release notes"
        }, 
        {
            "location": "/CHANGELOG/#release-notes", 
            "text": "", 
            "title": "Release Notes"
        }, 
        {
            "location": "/CHANGELOG/#version-011", 
            "text": "Changes :   Adds  use_unique_id  option when creating a Job object. This will then create a separate error, log, and output file for each of the arguments in the Job  args  list.  Adds  extra_lines  option when creating a Dagman object (similar to the Job object).  Replaces all occurances of  os.system()  with  subprocess.Popen() . This won't affect anything the user touches, just modernizing under-the-hood stuff.", 
            "title": "Version 0.1.1"
        }, 
        {
            "location": "/CHANGELOG/#version-010", 
            "text": "Changes :   Adds  request_cpus  attribute to Job object to make it easier to request a specified number of CPUs.  Adds  pycondor.get_queue()  feature to get  condor_q  information.  Job and Dagman object methods now return  self .  Fixed typo in logger formatting.", 
            "title": "Version 0.1.0"
        }
    ]
}